{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c96e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d21eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = pd.read_csv(f'./input/enron/messages.csv').fillna(' ')\n",
    "X_enron = np.array(enron['message'])\n",
    "y_enron = np.array(enron['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1227d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_spam = pd.read_csv(f'./input/ling_spam_copy/messages.csv').fillna(' ')\n",
    "X_ling_spam = np.array(ling_spam['message'])\n",
    "y_ling_spam = np.array(ling_spam['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14e4192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_assasin = pd.read_csv(f'./input/spam_assasin_copy/messages.csv').fillna(' ')\n",
    "X_spam_assasin = np.array(spam_assasin['message'])\n",
    "y_spam_assasin = np.array(spam_assasin['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90744c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e657520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mealpy.swarm_based import AO, HGS, SSA, MRFO, HHO\n",
    "\n",
    "def resolve_dataset(name):\n",
    "    if (name == 'enron'):\n",
    "        return [X_enron, y_enron]\n",
    "    elif (name == 'ling_spam'):\n",
    "        return [X_ling_spam, y_ling_spam]\n",
    "    elif (name == 'spam_assasin'):\n",
    "        return [X_spam_assasin, y_spam_assasin]\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def resolve_clf(alg):\n",
    "    if alg == 'AO':\n",
    "        return AO.OriginalAO\n",
    "    elif alg == 'HGS':\n",
    "        return HGS.OriginalHGS\n",
    "    elif alg == 'SSA':\n",
    "        return SSA.OriginalSSA\n",
    "    elif alg == 'MRFO':\n",
    "        return MRFO.BaseMRFO\n",
    "    elif alg == 'HHO':\n",
    "        return HHO.BaseHHO\n",
    "\n",
    "\n",
    "def test_bio_alg(clf, obj_function):\n",
    "    problem = {\n",
    "        'obj_func': obj_function,\n",
    "        'lb': [0.0001, 0.0001, 0.0001],\n",
    "        'ub': [1000, 1000, 1000],\n",
    "        'minmax': 'max',\n",
    "        'verbose': True,\n",
    "    }\n",
    "    model = clf(problem, epoch=10, pop_size=40)\n",
    "    model.solve()\n",
    "    return model.g_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9deb2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(alg, dataset):\n",
    "    [X, y] = resolve_dataset(dataset)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    if (alg == 'RSCV'):\n",
    "        tuned_parameters = {\n",
    "            'epsilon': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'tol': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "        }\n",
    "\n",
    "        clf = Pipeline([\n",
    "            ('tfidf_vectorizer', TfidfVectorizer(\n",
    "                stop_words=stopwords.words('english'))),\n",
    "            ('classificator', SGDClassifier(random_state=0, alpha=alpha, epsilon=epsilon, tol=tol))])\n",
    "    \n",
    "        model = RandomizedSearchCV(clf, tuned_parameters, scoring='accuracy', random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        params = model.best_params_\n",
    "        return [params['alpha'], params['epsilon'], params['tol']]\n",
    "    \n",
    "    elif alg == \"DEFAULT\":\n",
    "        return [0.0001, 0.1, 1e-3]\n",
    "\n",
    "    def obj_function(solution):\n",
    "        alpha, epsilon, tol = solution\n",
    "        clf = Pipeline([\n",
    "            ('tfidf_vectorizer', TfidfVectorizer(\n",
    "                stop_words=stopwords.words('english'))),\n",
    "            ('classificator', SGDClassifier(random_state=0, alpha=alpha, epsilon=epsilon, tol=tol))])\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    clf = resolve_clf(alg)\n",
    "    best_params_ = test_bio_alg(clf, obj_function)\n",
    "\n",
    "    return best_params_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04e217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def test(train, test, alg): \n",
    "    [X, y] = resolve_dataset(train)\n",
    "    [X2, y2] = resolve_dataset(test)\n",
    "\n",
    "    params = get_best(alg, train)\n",
    "\n",
    "    # split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25)\n",
    "\n",
    "    clf = Pipeline([\n",
    "        ('tfidf_vectorizer', TfidfVectorizer(\n",
    "            stop_words=stopwords.words('english'))),\n",
    "        ('classificator', SGDClassifier(random_state=0, alpha=params[0], epsilon=params[1], tol=params[2]))])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    y2_pred = clf.predict(X2_)\n",
    "\n",
    "    test_acc = accuracy_score(y2, y2_pred)\n",
    "    test_prec = precision_score(y2, y2_pred)\n",
    "    test_recall = recall_score(y2, y2_pred)\n",
    "    test_f1 = f1_score(y2, y2_pred)\n",
    "\n",
    "    print(f'Acc: {acc} Prec: {prec} Recall: {recall} F1: {f1}')\n",
    "    print(\n",
    "        f'AccTest: {test_acc} PrecTest: {test_prec} RecallTest: {test_recall} F1Test: {test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c03ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch: 1, Current best: 0.9982471516213848, Global best: 0.9982471516213848, Runtime: 53.53998 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspam_assasin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mling_spam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMRFO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(train, test, alg)\u001b[0m\n\u001b[1;32m      4\u001b[0m [X, y] \u001b[38;5;241m=\u001b[39m resolve_dataset(train)\n\u001b[1;32m      5\u001b[0m [X2, y2] \u001b[38;5;241m=\u001b[39m resolve_dataset(test)\n\u001b[0;32m----> 7\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mget_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# split dataset\u001b[39;00m\n\u001b[1;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     11\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mget_best\u001b[0;34m(alg, dataset)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, y_pred)\n\u001b[1;32m     37\u001b[0m clf \u001b[38;5;241m=\u001b[39m resolve_clf(alg)\n\u001b[0;32m---> 38\u001b[0m best_params_ \u001b[38;5;241m=\u001b[39m \u001b[43mtest_bio_alg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_params_[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mtest_bio_alg\u001b[0;34m(clf, obj_function)\u001b[0m\n\u001b[1;32m     27\u001b[0m problem \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj_func\u001b[39m\u001b[38;5;124m'\u001b[39m: obj_function,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlb\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m }\n\u001b[1;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m clf(problem, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mg_best\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mealpy/optimizer.py:120\u001b[0m, in \u001b[0;36mOptimizer.solve\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_evolve(epoch)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m## Evolve method will be called in child class\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m## Call after evolve function\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_evolve(epoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mealpy/swarm_based/MRFO.py:78\u001b[0m, in \u001b[0;36mBaseMRFO.evolve\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     76\u001b[0m     pos_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamend_position_faster(x_t1)\n\u001b[1;32m     77\u001b[0m     pop_new\u001b[38;5;241m.\u001b[39mappend([pos_new, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m---> 78\u001b[0m pop_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_fitness_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m pop_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgreedy_selection_population(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop, pop_new)\n\u001b[1;32m     80\u001b[0m _, g_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_global_best_solution(pop_new, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mealpy/optimizer.py:227\u001b[0m, in \u001b[0;36mOptimizer.update_fitness_population\u001b[0;34m(self, pop)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pop):\n\u001b[0;32m--> 227\u001b[0m         pop[idx][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mID_FIT] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fitness_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pop\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mealpy/optimizer.py:252\u001b[0m, in \u001b[0;36mOptimizer.get_fitness_solution\u001b[0;34m(self, solution)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fitness_solution\u001b[39m(\u001b[38;5;28mself\u001b[39m, solution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m        solution (list): A solution with format [position, [target, [obj1, obj2, ...]]]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m        [target, [obj1, obj2, ...]]\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fitness_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mID_POS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mealpy/optimizer.py:238\u001b[0m, in \u001b[0;36mOptimizer.get_fitness_position\u001b[0;34m(self, position)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fitness_position\u001b[39m(\u001b[38;5;28mself\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m        position (nd.array): 1-D numpy array\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m        [target, [obj1, obj2, ...]]\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mobj_is_list:\n\u001b[1;32m    240\u001b[0m         objs \u001b[38;5;241m=\u001b[39m [objs]\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mget_best.<locals>.obj_function\u001b[0;34m(solution)\u001b[0m\n\u001b[1;32m     27\u001b[0m alpha, epsilon, tol \u001b[38;5;241m=\u001b[39m solution\n\u001b[1;32m     28\u001b[0m clf \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     29\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_vectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(\n\u001b[1;32m     30\u001b[0m         stop_words\u001b[38;5;241m=\u001b[39mstopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))),\n\u001b[1;32m     31\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassificator\u001b[39m\u001b[38;5;124m'\u001b[39m, SGDClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, alpha\u001b[38;5;241m=\u001b[39malpha, epsilon\u001b[38;5;241m=\u001b[39mepsilon, tol\u001b[38;5;241m=\u001b[39mtol))])\n\u001b[0;32m---> 33\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \n\u001b[1;32m   2060\u001b[0m \u001b[38;5;124;03mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m-> 2077\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1200\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1202\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:115\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    113\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(train='spam_assasin', test='ling_spam', alg='MRFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f64373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
