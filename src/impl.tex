\section{Программная реализация тестовой системы}

Основные этапы работы программы:

\begin{itemize}
    \item[—] Считывание и преобразования данных с помощью библиотек numpy и pandas;
    \item[—] Преобразование текста в числовую матрицу слов с использованием TfidfVectorizer\cite{scikitTfIdf} и набора стоп-слов от
        модуля nltk;
    \item[—] Настройка параметров использованием подхода Scikit-Learn \cite{scikitSGD} и био-алгоритмов
        для повышения точности моделей;
    \item[—] Использование природных алгоритмов в реализации от модуля \\mealpy \cite{thieu_nguyen_2020_3711949};
    \item[—] Запись результатов.
\end{itemize}

\subsection{Настройка параметров модели}

Параметры настройки модели имеют большое влияние на обнаружение спам-писем и скорость обучения. Станадртные
алгоритмы настройки предлагают 3 параметра для алгоритма SGD:

\begin{itemize}
    \item[—] Альфа (alpha) — чем выше значение, тем сильнее регуляризация. Также может использоваться для вычисления скорости обучения;
    \item[—] Эпсилон (epsilon) — значение определяет скорость обучения алгоритма;
    \item[—] Тол (tol) — критерий остановки.
\end{itemize}

Настройка модели проводилась с использованием:

\begin{itemize}
    \item[—] Параметров по умолчанию;
    \item[—] Случайного поиска (подраздел \ref{optimization});
    \item[—] Природных алгоритмов (раздел \ref{BIOAlgs}).
\end{itemize}

Границы для всех трех параметров были установлены $10^{-3}$ до $10^3$ с шагом в одну степень.
Набор был разделен на тренировочный и тестовый в отношении 75:25. Для усреднения результатов по
Для всех комбинаций набора данных и подхода к настройке классификатора обучение проводилось 100 раз. 
За результат была принята медиана всех итераций.

Недостатки использования случайного поиска и поиска по сетке очевидны — и тот, и дргуой используют и возвращают только те
параметры, которые им переданы в качестве словаря, с той лишь разницей, что случайный поиск не предполагает полного перебора,
а потому в нашем случае гораздо быстрее, чем поиск по сетке.
Но наиболее удачная комбинация параметров может и не принадлежать переданным вариациям. Для поиска внутри области,
а не по точкам, используем природные алгоритмы.

\subsection{Применение природных алгоритмов оптимизации}

В контексте данной работы задача оптимизации — максимизировать метрическую функцию (подраздел \ref{Scorer}).
В качестве такой функции $Accuracy$ не слишком полезна в задачах с несоразмерными классами, 
а в наборах данных доля спама часто значительно ниже доли полезных писем \ref{datasets}. Поэтому $Precision$ и 
$Recall$ будут более полезны в оценке. Поэтому была испольщована $F1-score$, представляющая собой их среднее гармоническое.

Алгоритмы оптимизации были запущены с числом частиц (epoch) равным 10 и числом популяций (pop\_size) равным 50.
Границы поиска для каждого параметра — от $10^{-3}$ до $10^3$.




