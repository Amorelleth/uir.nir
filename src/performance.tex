\section{Оценка производительности моделей машинного обучения}\label{Section:Performance}

Для оценки производительности некоторой обученной модели используются различные метрики.

\subsection{Матрица ошибок}

Обнаружение спама в электронных письмах можно оценить с помощью
различных показателей эффективности. Матрица ошибок используется для
визуализации работы алгоритмов и может быть определена как в Таблице \ref{table1}.

\begin{table}[!ht]
    \centering
    \caption{Матрица ошибок}
    \begin{tabular}{|p{0.3\textwidth}|p{0.3\textwidth}|p{0.3\textwidth}|}
    \hline
        — & HAM & SPAM \\ \hline
        HAM & TN & FP \\ \hline
        SPAM & FN & TP \\ \hline
    \end{tabular}
    \label{table1}
\end{table}
где:

\begin{itemize}
    \item[—] TN = TrueNegative — Письма, распознанные как письма;
    \item[—] FP = FalsePositive — Спам-письма, распознанные как письма;
    \item[—] FN = FalseNegative — Письма, распознанные как спам-письма;
    \item[—] TP = TruePositive — Спам-письма, распознанные как спам-письма.
\end{itemize}


\subsection{Точность (Accuracy)}

Точность — это отношение количества правильных прогнозов к общему количеству входных
выборок \cite{scikitMetrics}:

\begin{equation}\label{eq11}
    Accuracy = {{(TN + TP)} \over{(TP + FN + FP + TN)}}
\end{equation}

\subsection{Recall}

Recall описывает, сколько писем было правильно отнесено к спаму из
общего количества писем, распознанных как спам $(TP + FN)$ \cite{scikitMetrics}:

\begin{equation}\label{eq12}
    Recall = {{TP} \over{(TP + FN)}}
\end{equation}

\subsection{Precision}

Измерение precision заключается в доли верно идентифицированного
спама из всех спам-писем $(TP + FP)$ \cite{scikitMetrics}. Определяется
уравнением:

\begin{equation}\label{eq13}
    Precision = {{TP} \over{(TP + FP)}}
\end{equation}

\subsection{F1-score}

Оценка $F1$ может быть интерпретирована как средневзвешенное
значение precision и recall, где оценка $F1$ достигает своего лучшего
значения при 1 и худшего значения при 0 \cite{scikitMetrics}.
Формула для оценки $F1$:

\begin{equation}\label{eq14}
    F1 = {2 \times (precision \times recall) \over{(precision + recall)}}
\end{equation}


\subsection{ROC-кривая} 

ROC-кривая (receiver operating characteristic curve) — также известна как кривая ошибок — график, показывающий 
производительность классификационной модели при всех пороговых значениях классификации. 
Часто используется при бинарной классификации. 
% TODO ref https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc

Кривая ошибок отображает два параметра:

\begin{itemize}
    \item[—] $TPR$ — Частота истинно-положительных срабатываний (Чувствительность);
    \item[—] $FPR$ — Частота ложно-положительных срабатываний (Ошибка первого рода).
\end{itemize}

$TPR$ — то же, что $Recall$\eqref{eq12}.
Величина $1 - FPR$ называется специфичность модели.

$FPR$ определяется формулой:

\begin{equation}\label{eq18}
    Precision = {{FP} \over{(FP + TN)}}
\end{equation}

Площадь под кривой ошибок (AUC ROC — area under curve ROC) — площадь двумерной области под  
кривой ошибок. Обеспечивает совокупную меру эффективности по всем возможным пороговым значениям классификации.

Чем выше показатель, тем качественнее классификатор. Значение колеблется от 0 до 1: модель, предсказания которой на 
100\% неверны, имеет $AUC=0.0$, модель, предсказания которой на 100\% верны, имеет $AUC=1.0$.

Преимущества использования AUC:

\begin{itemize}
    \item[—] Является масштабно-инвариантным. Измеряет, насколько хорошо ранжируются прогнозы, а не их абсолютные значения.
    \item[—] Является классификационно-пороговым инвариантом. Измеряет качество предсказаний модели независимо от того, 
    какой порог классификации выбран.
\end{itemize}


\subsection{Перекрестная проверка}

Перекрестная проверка применяется для получения более надежных оценок.

В базовом подходе, называемом $k-fold CV$ \cite{scikitKFold}, 
обучающая выборка разбивается на k меньших наборов. 

Для каждого из k наборов выполняется следующее:

\begin{itemize}
    \item[—] Модель обучается с использованием $k - 1$ частей набора в качестве обучающих данных;
    \item[—] Полученная модель проверяется на оставшейся части данных (то есть используется в качестве тестового набора для вычисления 
показателя производительности).
\end{itemize}

Метрика, которую возвращает k-кратная перекрестная проверка, представляет собой среднее значение из полученных значений этой метрики 
для всех k наборов. Этот подход может быть дорогостоящим в вычислительном отношении, но дает более точную оценку модели.

Вариацией данного метода является стратифицированная перекрестная проверка \cite{stratifiedKFold}, возвращающая наборы данных с  
сохранением процентного соотношения образцов для каждого класса.
